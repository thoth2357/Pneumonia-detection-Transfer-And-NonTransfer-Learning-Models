{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing modules\n",
    "import re\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import warnings \n",
    "import tqdm\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.optimizers import Adam, Adadelta\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, Activation, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "if tf.test.gpu_device_name():\n",
    "    print('GPU found')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA INFORMATION AND PATH\n",
    "\n",
    "# Root directory of the procondect\n",
    "BASE_DIR = os.path.abspath(\"./\")\n",
    "\n",
    "# Data directory of the project\n",
    "DATA_DIR =  os.path.join(BASE_DIR, \"Dataset/data-task1\")\n",
    "\n",
    "# dataset respective directory\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
    "TEST_DIR = os.path.join(DATA_DIR, \"test\")\n",
    "VAL_DIR = os.path.join(DATA_DIR, \"val\")\n",
    "\n",
    "BATCH_SIZE = 30\n",
    "\n",
    "# Use small images for faster training. Set the limits of the small side\n",
    "# the large side, and that determines the image shape.\n",
    "IMAGE_MIN_DIM = 224\n",
    "IMAGE_MAX_DIM = 224\n",
    "\n",
    "#EPOCHS FOR MODEL\n",
    "EPOCHS = 30\n",
    "# Summary of Data information\n",
    "#TODO TASK: 'Put summary of data information here later' .time:2022-04-22  13:43:01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting plot parameters for plt\n",
    "fig, ax = plt.subplots(2, 3, figsize=(15, 7))\n",
    "ax = ax.ravel()\n",
    "plt.tight_layout()\n",
    "\n",
    "#plotting random non-pneumonia and pneumonia images from our train, test, and val to see how much different they look to our eye\n",
    "for i, dir_ in enumerate(glob.glob(f'{DATA_DIR}/*')):\n",
    "    ax[i].imshow(plt.imread(dir_ + '/no_pneumonia/' +next(os.walk(dir_+'/no_pneumonia/'))[2][0]))\n",
    "    ax[i].set_title(f'Set: {dir_.split(\"/\")[-1]}, Condition: no_pneumonia')\n",
    "\n",
    "    ax[i+3].imshow(plt.imread(dir_ + '/pneumonia/' +next(os.walk(dir_+'/pneumonia/'))[2][0]))\n",
    "    ax[i+3].set_title(f'Set: {dir_.split(\"/\")[-1]}, Condition: pneumonia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parsing and storing datasets into variable\n",
    "non_pneumonia_train = glob.glob(f'{TRAIN_DIR}/no_pneumonia/*.png')\n",
    "pneumonia_train = glob.glob(f'{TRAIN_DIR}/no_pneumonia/*.png')\n",
    "\n",
    "\n",
    "#Basic EDA -Descriptive\n",
    "for i in glob.glob(f'{DATA_DIR}/*'):\n",
    "    non_pneumonia_images_count = len(glob.glob(i+'/no_pneumonia/*.png'))\n",
    "    pneumonia_images_count = len(glob.glob(i+'/pneumonia/*.png'))\n",
    "    print(f'{i.split(\"/\")[-1]} Dataset \\n Non-pneumonia images: {non_pneumonia_images_count} \\n pneumonia images: {pneumonia_images_count} \\n')\n",
    "\n",
    "    x = ['pneumonia', 'Non-pneumonia']\n",
    "    y = [pneumonia_images_count, non_pneumonia_images_count]\n",
    "    plt.bar(x, y)\n",
    "    plt.title('pneumonia vs non pneumonia')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('Classes')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA AUGMENTATION\n",
    "'''\n",
    "AUGMENTATION IS A PRACTIVE THAT ALLOWS US TO INCREASE THE SIZE OF HTE TRAINING SET.AUGMENTING THE TRAINING EXAMPLES ALLOWS THE MOD\n",
    "MODEL TO SEE OUR DATASET IMAGES IN A MORE DIVERSE WAYS. AUGMENTATION ALSO ALLOWS US TO CREATE A LARGER DATASET FOR OUR MODEL TO \n",
    "TRAIN ON. \n",
    "'''\n",
    "train_data_gen = ImageDataGenerator(\n",
    "    rescale = 1/255,\n",
    "    shear_range=10,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.5,2.0],\n",
    "    width_shift_range = 0.2,\n",
    "    rotation_range=20,\n",
    "    fill_mode = 'nearest'\n",
    ")\n",
    "\n",
    "val_test_data_gen = ImageDataGenerator(\n",
    "    rescale = 1/255,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 2 classes.\n",
      "Found 500 images belonging to 2 classes.\n",
      "Found 500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_images = train_data_gen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=(IMAGE_MIN_DIM, IMAGE_MAX_DIM),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'binary',\n",
    "    # shuffle=True,\n",
    "    # color_mode=\"grayscale\"\n",
    ")\n",
    "\n",
    "test_images = val_test_data_gen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(IMAGE_MIN_DIM, IMAGE_MAX_DIM),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'binary',\n",
    "    # shuffle=True,\n",
    "    # color_mode=\"grayscale\"\n",
    ")\n",
    "\n",
    "validation_images = val_test_data_gen.flow_from_directory(\n",
    "    VAL_DIR,\n",
    "    target_size=(IMAGE_MIN_DIM, IMAGE_MAX_DIM),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    class_mode = 'binary',\n",
    "    # shuffle=True,\n",
    "    # color_mode=\"grayscale\"\n",
    ")\n",
    "# next(train_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(IMAGE_MIN_DIM, IMAGE_MAX_DIM, 3))\n",
    "\n",
    "# First conv block\n",
    "x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\n",
    "x = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Second conv block\n",
    "x = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Third conv block\n",
    "x = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Fourth conv block\n",
    "x = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(rate=0.2)(x)\n",
    "\n",
    "# Fifth conv block\n",
    "x = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPool2D(pool_size=(2, 2))(x)\n",
    "x = Dropout(rate=0.2)(x)\n",
    "\n",
    "# FC layer\n",
    "x = Flatten()(x)\n",
    "x = Dense(units=512, activation='relu')(x)\n",
    "x = Dropout(rate=0.7)(x)\n",
    "x = Dense(units=128, activation='relu')(x)\n",
    "x = Dropout(rate=0.5)(x)\n",
    "x = Dense(units=64, activation='relu')(x)\n",
    "x = Dropout(rate=0.3)(x)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(units=1, activation='softmax')(x)\n",
    "\n",
    "# METRICS = [\n",
    "#       tf.keras.metrics.TruePositives(name='tp'),\n",
    "#       tf.keras.metrics.FalsePositives(name='fp'),\n",
    "#       tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "#       tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "#       tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "#       tf.keras.metrics.Precision(name='precision'),\n",
    "#       tf.keras.metrics.Recall(name='recall'),\n",
    "#       tf.keras.metrics.AUC(name='auc'),\n",
    "# ]\n",
    "\n",
    "# Creating model and compiling\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.summary()\n",
    "# plot_model(model,show_shapes=True, show_layer_names=True, rankdir='TB', expand_nested=True)\n",
    "\n",
    "\n",
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint(filepath='best_weights.hdf5', save_best_only=True, save_weights_only=True)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2, verbose=2, mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=1, mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 500\n",
    "img_height = 500\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(img_width, img_height, 3)))\n",
    "cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "cnn.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(img_width, img_height, 3)))\n",
    "cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "cnn.add(Conv2D(32, (3, 3), activation=\"relu\", input_shape=(img_width, img_height, 3)))\n",
    "cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "cnn.add(Conv2D(64, (3, 3), activation=\"relu\", input_shape=(img_width, img_height, 3)))\n",
    "cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "cnn.add(Conv2D(64, (3, 3), activation=\"relu\", input_shape=(img_width, img_height, 3)))\n",
    "cnn.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(activation = 'relu', units = 128))\n",
    "cnn.add(Dense(activation = 'relu', units = 64))\n",
    "cnn.add(Dense(activation = 'sigmoid', units = 1))\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "cnn.summary()\n",
    "plot_model(cnn,show_shapes=True, show_layer_names=True, rankdir='TB', expand_nested=True)\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=3)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor=\"val_loss\", patience = 2, verbose=1,factor=0.3, min_lr=0.000001)\n",
    "callbacks_list = [ early, learning_rate_reduction]\n",
    "\n",
    "weights = compute_class_weight('balanced', np.unique(train_images.classes), train_images.classes)\n",
    "cw = dict(zip( np.unique(train_images.classes), weights))\n",
    "print(cw)\n",
    "\n",
    "cnn.fit(\n",
    "    train_images,\n",
    "    epochs=3, \n",
    "    validation_data=validation_images, \n",
    "    class_weight=cw, \n",
    "    callbacks=callbacks_list\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "history1 = model.fit(\n",
    "    train_images,\n",
    "    epochs = EPOCHS,\n",
    "    steps_per_epoch = train_images.samples // BATCH_SIZE,\n",
    "    validation_data = validation_images,\n",
    "    # validation_steps = test_images.samples // BATCH_SIZE,\n",
    "    callbacks = [checkpoint, lr_reducer, early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATING CNN MODEL\n",
    "\n",
    "score = model.evaluate(train_images)\n",
    "\n",
    "print(\"Train Loss: \", score[0])\n",
    "print(\"Train Accuracy: \", score[1])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('EVALUATION OF MODEL')\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history1.history['loss'], label='Loss')\n",
    "plt.plot(history1.history['val_loss'], label='Val_Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss Evolution')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(history1.history['accuracy'], label='Accuracy')\n",
    "plt.plot(history1.history['val_accuracy'], label='Val_Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy Evolution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_images)\n",
    "\n",
    "acc = accuracy_score(test_labels, np.round(preds))*100\n",
    "cm = confusion_matrix(test_labels, np.round(preds))\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print('CONFUSION MATRIX ------------------')\n",
    "print(cm)\n",
    "\n",
    "print('\\nTEST METRICS ----------------------')\n",
    "precision = tp/(tp+fp)*100\n",
    "recall = tp/(tp+fn)*100\n",
    "print('Accuracy: {}%'.format(acc))\n",
    "print('Precision: {}%'.format(precision))\n",
    "print('Recall: {}%'.format(recall))\n",
    "print('F1-score: {}'.format(2*precision*recall/(precision+recall)))\n",
    "\n",
    "print('\\nTRAIN METRIC ----------------------')\n",
    "print('Train acc: {}'.format(np.round((hist.history['acc'][-1])*100, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model = tf.keras.applications.VGG19(\n",
    "    weights='imagenet',\n",
    "    include_top = False,\n",
    "#     input_shape = (224,224,3)\n",
    ")\n",
    "\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "x = vgg_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "# output layer\n",
    "predictions = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model2 = tf.keras.Model(inputs=vgg_model.input, outputs=predictions)\n",
    "\n",
    "# to avoid overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=10)\n",
    "lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',patience=8)\n",
    "\n",
    "# Compiling the model\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "93/93 [==============================] - 2332s 25s/step - loss: 0.5066 - accuracy: 0.7889 - val_loss: 0.4814 - val_accuracy: 0.7800 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "93/93 [==============================] - 2473s 27s/step - loss: 0.4794 - accuracy: 0.7853 - val_loss: 0.4951 - val_accuracy: 0.7640 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "93/93 [==============================] - 2615s 28s/step - loss: 0.4766 - accuracy: 0.7857 - val_loss: 0.4682 - val_accuracy: 0.7740 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "93/93 [==============================] - 2679s 29s/step - loss: 0.4816 - accuracy: 0.7835 - val_loss: 0.4915 - val_accuracy: 0.7800 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "93/93 [==============================] - 2196s 24s/step - loss: 0.4716 - accuracy: 0.7846 - val_loss: 0.4612 - val_accuracy: 0.7820 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "88/93 [===========================>..] - ETA: 1:56 - loss: 0.4588 - accuracy: 0.7920"
     ]
    }
   ],
   "source": [
    "history_vgg = model2.fit(train_images,epochs=30, \n",
    "                    validation_data=validation_images,\n",
    "                     steps_per_epoch=100,\n",
    "                    callbacks=[early_stopping,lr],\n",
    "                    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = tf.keras.applications.ResNet50V2(\n",
    "    weights='imagenet',\n",
    "    include_top = False,\n",
    "    input_shape = (224,224,3)\n",
    ")\n",
    "\n",
    "for layer in resnet_model.layers:\n",
    "    layer.trainable=False\n",
    "    \n",
    "x = resnet_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dense(128,activation='relu')(x)\n",
    "# output layer\n",
    "predictions = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n",
    "\n",
    "model3 = tf.keras.Model(inputs=resnet_model.input, outputs=predictions)\n",
    "\n",
    "# to avoid overfitting\n",
    "# early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=6)\n",
    "\n",
    "# Compiling the model\n",
    "model3.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 727s 7s/step - loss: 0.4715 - accuracy: 0.7863 - val_loss: 0.4305 - val_accuracy: 0.7960 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 644s 6s/step - loss: 0.4213 - accuracy: 0.8070 - val_loss: 0.4056 - val_accuracy: 0.8140 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 780s 8s/step - loss: 0.4067 - accuracy: 0.8153 - val_loss: 0.4073 - val_accuracy: 0.8040 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 734s 7s/step - loss: 0.4101 - accuracy: 0.8117 - val_loss: 0.4162 - val_accuracy: 0.8120 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 810s 8s/step - loss: 0.4075 - accuracy: 0.8157 - val_loss: 0.4155 - val_accuracy: 0.8120 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 889s 9s/step - loss: 0.4039 - accuracy: 0.8157 - val_loss: 0.3989 - val_accuracy: 0.8180 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 686s 7s/step - loss: 0.4102 - accuracy: 0.8150 - val_loss: 0.4066 - val_accuracy: 0.8280 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 673s 7s/step - loss: 0.3987 - accuracy: 0.8153 - val_loss: 0.4076 - val_accuracy: 0.8120 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 643s 6s/step - loss: 0.3976 - accuracy: 0.8127 - val_loss: 0.4038 - val_accuracy: 0.8200 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 586s 6s/step - loss: 0.3905 - accuracy: 0.8200 - val_loss: 0.4078 - val_accuracy: 0.8180 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 629s 6s/step - loss: 0.3890 - accuracy: 0.8273 - val_loss: 0.4152 - val_accuracy: 0.8200 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 629s 6s/step - loss: 0.3912 - accuracy: 0.8227 - val_loss: 0.4077 - val_accuracy: 0.8160 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 641s 6s/step - loss: 0.3981 - accuracy: 0.8230 - val_loss: 0.4063 - val_accuracy: 0.8120 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 753s 8s/step - loss: 0.3928 - accuracy: 0.8297 - val_loss: 0.4309 - val_accuracy: 0.8040 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 630s 6s/step - loss: 0.3886 - accuracy: 0.8277 - val_loss: 0.4075 - val_accuracy: 0.8200 - lr: 1.0000e-04\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 588s 6s/step - loss: 0.3858 - accuracy: 0.8220 - val_loss: 0.4068 - val_accuracy: 0.8220 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "history3 = model3.fit(train_images,epochs=30,\n",
    "                    validation_data=validation_images,\n",
    "                     steps_per_epoch=100,\n",
    "                    callbacks=[early_stopping,lr],\n",
    "                    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the data in X_train, y_train variables by iterating over the batches\n",
    "train_images.reset()\n",
    "X_train, y_train = next(train_images)\n",
    "for i in tqdm(range(int(len(train_images)/BATCH_SIZE)-1)): #1st batch is already fetched before the for loop.\n",
    "  img, label = next(train_images)\n",
    "  X_train = np.append(X_train, img, axis=0 )\n",
    "  y_train = np.append(y_train, label, axis=0)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.reset()\n",
    "X_train, y_train = next(train_images)\n",
    "for i in tqdm(range(int(len(train_images)/BATCH_SIZE)-1)): #1st batch is already fetched before the for loop.\n",
    "  img, label = next(train_images)\n",
    "  X_train = np.append(X_train, img, axis=0 )\n",
    "  y_train = np.append(y_train, label, axis=0)\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN CLASSIFIER -- BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn  = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "predictions = knn.predict()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9013e23377c4df86dc09c341e3e8e9dd81c02c4de203807e1a62a3a9bc38c81"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
